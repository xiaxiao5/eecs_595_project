{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make my annotation (narrations.csv and groups.csv) from egoclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from dataset import SRLPredictor\n",
    "import numpy as np\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_narration_df = pd.read_csv(\"../dataset/egoclip.csv\", sep='\\t', on_bad_lines='warn')\n",
    "all_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a subset as example\n",
    "all_narration_df = all_narration_df.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_narration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of videos\n",
    "len(all_narration_df['video_uid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narration column name\n",
    "narration_column_name = 'clip_text' # 'narration_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process narration text\n",
    "# # del start #C/#O\n",
    "all_narration_df[narration_column_name] = all_narration_df[narration_column_name].str.split(' ', n=1).str[1]\n",
    "# skip those contain unsure\n",
    "all_narration_df = all_narration_df[-all_narration_df[narration_column_name].str.contains('#unsure')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# srl_results = srl(['a cat eats food', 'a dog eats food'])\n",
    "slrpredictor = SRLPredictor('cpu')\n",
    "srl_results = slrpredictor.predict(all_narration_df[narration_column_name].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dict\n",
    "len(srl_results), srl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrase into dataframe\n",
    "srl_df = {}\n",
    "dropped_sentence_no = []\n",
    "for sentence_no, srl_result in enumerate(srl_results):\n",
    "    if srl_result['verbs'] == []:\n",
    "        dropped_sentence_no.append(sentence_no)\n",
    "        continue\n",
    "    srl_matching = list(zip(srl_result['verbs'][0]['tags'], srl_result['words'])) # e.g., {'B-ARG0': '#', 'I-ARG0': 'C', 'B-V': 'interacts', 'B-ARG1': 'with', 'I-ARG1': 'X'}\n",
    "\n",
    "    for srl_full_tag, srl_word in srl_matching:\n",
    "        srl_tag = srl_full_tag.split('-')[-1]\n",
    "\n",
    "        if srl_tag not in srl_df:\n",
    "            srl_df[srl_tag] = {}\n",
    "        if sentence_no not in srl_df[srl_tag]:\n",
    "            srl_df[srl_tag][sentence_no] = []\n",
    "        srl_df[srl_tag][sentence_no].append(srl_word)\n",
    "\n",
    "srl_df = pd.DataFrame(srl_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many narrations are left after applying SRL. Some narrations are not phrased baecause of the SRL method\n",
    "len(srl_df) / len(all_narration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of narrations are not SRL-ed\n",
    "len(all_narration_df.iloc[dropped_sentence_no, :]) / len(all_narration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-SRL-ed narrations\n",
    "all_narration_df.iloc[dropped_sentence_no, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat narration and SRL\n",
    "complete_srl_df = pd.concat([all_narration_df, srl_df], axis=1)\n",
    "complete_srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with too many NaNs. drop rows >= 1 NaNs after dropping columns with too many NaNs. \n",
    "threshold = 0.9\n",
    "clean_srl_df = complete_srl_df.dropna(axis=1, thresh=len(srl_df)*threshold).dropna(axis=0)\n",
    "clean_srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many narrations are left who have at least SVO format\n",
    "len(clean_srl_df) / len(all_narration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "save_srl_df = clean_srl_df.reset_index(drop=True)\n",
    "save_srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_path = '../dataset/egoclip_srl.csv'\n",
    "save_srl_df.to_csv(srl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group narrations based on taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load taxonomy\n",
    "taxonomy_verb_path = '/z/dat/Ego4D/raw/v2/annotations/narration_verb_taxonomy.csv'\n",
    "taxonomy_verb_df = pd.read_csv(taxonomy_verb_path)\n",
    "taxonomy_verb_df['group'] = taxonomy_verb_df['group'].apply(ast.literal_eval)\n",
    "\n",
    "taxonomy_noun_path = \"/z/dat/Ego4D/raw/v2/annotations/narration_noun_taxonomy.csv\"\n",
    "taxonomy_noun_df = pd.read_csv(taxonomy_noun_path)\n",
    "taxonomy_noun_df['group'] = taxonomy_noun_df['group'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_verb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tagged verb and noun into list\n",
    "save_srl_df['tag_verb'] = save_srl_df['tag_verb'].apply(ast.literal_eval)\n",
    "save_srl_df['tag_noun'] = save_srl_df['tag_noun'].apply(ast.literal_eval)\n",
    "\n",
    "# make SRL chunks into one string\n",
    "save_srl_df['ARG0'] = save_srl_df['ARG0'].apply(' '.join)\n",
    "save_srl_df['V'] = save_srl_df['V'].apply(' '.join)\n",
    "save_srl_df['ARG1'] = save_srl_df['ARG1'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_srl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_verb_df.iloc[[17, 68]\t, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each narration, find the verb group and noun group\n",
    "from dataset import grouping\n",
    "grouping_results = save_srl_df.apply(grouping, args=(taxonomy_verb_df, taxonomy_noun_df), axis=1)\n",
    "grouping_results_df = pd.DataFrame({'valid_tag_noun': grouping_results})\n",
    "grouping_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the grouping results with other columns\n",
    "grouped_narration_df = pd.concat([save_srl_df, grouping_results_df], axis=1)\n",
    "grouped_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.893)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post process\n",
    "clean_narration_df = grouped_narration_df.dropna(axis=0)\n",
    "# see how many narrations have tagged noun\n",
    "len(clean_narration_df) / len(grouped_narration_df), len(clean_narration_df) / len(all_narration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as narrations.csv\n",
    "clean_narration_df.to_csv('../dataset/egoclip_narrations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make exploed narrations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_narration_df = pd.read_csv('../dataset/egoclip_narrations.csv', index_col=0)\n",
    "clean_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to list\n",
    "clean_narration_df['valid_tag_noun'] = clean_narration_df['valid_tag_noun'].apply(ast.literal_eval)\n",
    "clean_narration_df['tag_verb'] = clean_narration_df['tag_verb'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_verb = clean_narration_df['tag_verb'].explode().reset_index()\n",
    "expanded_noun = clean_narration_df['valid_tag_noun'].explode().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_merged = pd.merge(expanded_verb, expanded_noun, on='index', how='outer')\n",
    "vn_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploed_narration_df = pd.merge(clean_narration_df, vn_merged, left_index=True, right_on='index').drop(columns=['index'])\n",
    "exploed_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploed the verb and noun elements so that each row belongs to one group\n",
    "exploed_narration_df = exploed_narration_df.rename(columns={\"tag_verb_x\": \"tag_verb_original\", \"valid_tag_noun_x\": \"valid_tag_noun_original\", \"tag_verb_y\": \"tag_verb_single\", \"valid_tag_noun_y\": \"valid_tag_noun_single\"})\n",
    "exploed_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save exploed narrations\n",
    "exploed_narration_df.to_csv('../dataset/egoclip_narrations_exploed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make groups.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make groups.csv\n",
    "group_df = exploed_narration_df.groupby(['tag_verb_single', 'valid_tag_noun_single']).apply(lambda x: x.index.tolist()).reset_index()\n",
    "group_df.columns = ['tag_verb', 'tag_noun', 'narration_indices']\n",
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploed_narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for_diff_noun(row, narration_df):\n",
    "    # Get the narrations with the same tag_verb\n",
    "    narrations_with_same_verb = narration_df[narration_df['tag_verb_single'] == row['tag_verb']]\n",
    "    \n",
    "    # Convert the current row's tag_noun to a list\n",
    "    # current_nouns = eval(row['tag_noun'])\n",
    "    current_nouns = row['tag_noun']\n",
    "    # Filter out the narrations which have any of the current group's tag_noun in their valid_tag_noun\n",
    "    filtered_narrations = narrations_with_same_verb[narrations_with_same_verb['valid_tag_noun_single']!=current_nouns]\n",
    "    \n",
    "    return filtered_narrations.index.tolist()\n",
    "\n",
    "group_df['mismatch_noun'] = group_df.apply(get_indices_for_diff_noun, args=(exploed_narration_df,), axis=1)\n",
    "\n",
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for_diff_verb(row, narration_df):\n",
    "    # Get the narrations with the same tag_noun\n",
    "    narrations_with_same_verb = narration_df[narration_df['valid_tag_noun_single'] == row['tag_noun']]\n",
    "    \n",
    "    # Convert the current row's tag_noun to a list\n",
    "    # current_nouns = eval(row['tag_noun'])\n",
    "    current_nouns = row['tag_verb']\n",
    "    # Filter out the narrations which have any of the current group's tag_noun in their valid_tag_noun\n",
    "    filtered_narrations = narrations_with_same_verb[narrations_with_same_verb['tag_verb_single']!=current_nouns]\n",
    "    \n",
    "    return filtered_narrations.index.tolist()\n",
    "\n",
    "group_df['mismatch_verb'] = group_df.apply(get_indices_for_diff_verb, args=(exploed_narration_df,), axis=1)\n",
    "\n",
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mismatch_verb_noun column\n",
    "def find_complement_set(sublist, corpora):\n",
    "    return [el for el in corpora if el not in sublist]\n",
    "group_df['mismatch_verb_noun'] = group_df['narration_indices'].apply(find_complement_set, args=(exploed_narration_df.index.tolist(),))\n",
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "group_df.to_csv('../dataset/egoclip_groups.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read narrations.csv and groups.csv\n",
    "narration_df = pd.read_csv('../dataset/egoclip_narrations_exploed.csv', index_col=0)\n",
    "group_df = pd.read_csv('../dataset/egoclip_groups.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_verb</th>\n",
       "      <th>tag_noun</th>\n",
       "      <th>narration_indices</th>\n",
       "      <th>mismatch_noun</th>\n",
       "      <th>mismatch_verb</th>\n",
       "      <th>mismatch_verb_noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>[947, 1024, 1040]</td>\n",
       "      <td>[17, 18, 33, 35, 36, 38, 39, 40, 57, 61, 64, 6...</td>\n",
       "      <td>[205, 206, 208, 209, 210, 211, 232, 233, 236, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tag_verb  tag_noun  narration_indices  \\\n",
       "34        11        49  [947, 1024, 1040]   \n",
       "\n",
       "                                        mismatch_noun  \\\n",
       "34  [17, 18, 33, 35, 36, 38, 39, 40, 57, 61, 64, 6...   \n",
       "\n",
       "                                        mismatch_verb  \\\n",
       "34  [205, 206, 208, 209, 210, 211, 232, 233, 236, ...   \n",
       "\n",
       "                                   mismatch_verb_noun  \n",
       "34  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random sample n groups\n",
    "sampled_groups = group_df.sample(n=1)\n",
    "sampled_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a dataframe to show group verb and noun labels (canonical), and show k narrations, k verb-mismatched, k noun-mismatched and k vn-mismatched narration rows in the group\n",
    "k = 2\n",
    "expanded_narr = sampled_groups['narration_indices'].apply(ast.literal_eval).explode().reset_index().sample(n=k)\n",
    "expanded_mis_v = sampled_groups['mismatch_verb'].apply(ast.literal_eval).explode().reset_index().sample(n=k)\n",
    "expanded_mis_n = sampled_groups['mismatch_noun'].apply(ast.literal_eval).explode().reset_index().sample(n=k)\n",
    "expanded_mis_vn = sampled_groups['mismatch_verb_noun'].apply(ast.literal_eval).explode().reset_index().sample(n=k)\n",
    "\n",
    "from functools import reduce\n",
    "indices_samples_df = reduce(lambda  left,right: pd.merge(left,right,on='index',\n",
    "                                            how='outer'), [expanded_narr, expanded_mis_v, expanded_mis_n, expanded_mis_vn])\n",
    "indices_samples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_groups_info_df = pd.merge(sampled_groups, indices_samples_df, left_index=True, right_on='index')\n",
    "sampled_groups_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get narration text\n",
    "sampled_groups_info_df['narration_indices_y_info'] = sampled_groups_info_df['narration_indices_y'].apply(lambda idx: narration_df.loc[idx, 'clip_text'])\n",
    "sampled_groups_info_df['mismatch_verb_y_info'] = sampled_groups_info_df['mismatch_verb_y'].apply(lambda idx: narration_df.loc[idx, 'clip_text'])\n",
    "sampled_groups_info_df['mismatch_noun_y_info'] = sampled_groups_info_df['mismatch_noun_y'].apply(lambda idx: narration_df.loc[idx, 'clip_text'])\n",
    "sampled_groups_info_df['mismatch_verb_noun_y_info'] = sampled_groups_info_df['mismatch_verb_noun_y'].apply(lambda idx: narration_df.loc[idx, 'clip_text'])\n",
    "sampled_groups_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group text\n",
    "taxonomy_verb_df = pd.read_csv(\"/z/dat/Ego4D/raw/v2/annotations/narration_verb_taxonomy.csv\")\n",
    "taxonomy_noun_df = pd.read_csv(\"/z/dat/Ego4D/raw/v2/annotations/narration_noun_taxonomy.csv\")\n",
    "sampled_groups_info_df['tag_verb_info'] = sampled_groups_info_df['tag_verb'].apply(lambda x: taxonomy_verb_df.iloc[x, :]['label'])\n",
    "sampled_groups_info_df['tag_noun_info'] = sampled_groups_info_df['tag_noun'].apply(lambda x: taxonomy_noun_df.iloc[x, :]['label'])\n",
    "sampled_groups_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "with pd.option_context('display.max_colwidth', None): # show full text\n",
    "    clean_sampled_groups_info_df = sampled_groups_info_df[['tag_verb_info', 'tag_noun_info', 'narration_indices_y_info', 'mismatch_verb_y_info', 'mismatch_noun_y_info', 'mismatch_verb_noun_y_info', \n",
    "                                                           'tag_verb', 'tag_noun', 'index', 'narration_indices_y', 'mismatch_verb_y', 'mismatch_noun_y', 'mismatch_verb_noun_y']]\n",
    "    display(clean_sampled_groups_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mistake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
